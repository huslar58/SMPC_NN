{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secure multiparty computation with neural networks\n",
    "\n",
    "The plaintext and SMPC neural networks implement the exemplary use case three in the main report.\n",
    "\n",
    "Below, the secure multiparty computation with 4 parties is implemented with the neural network defined in Plain_NN. The neural network architecture is identical to pytorch, the only difference being that the crypten API is being used.\n",
    "The neural network architecture and training was build and experimented with by the author based on the tutorials provided by the contributors and creators of the Crypten library. (B. Knott and S. Venkataraman and A.Y. Hannun and S. Sengupta and M. Ibrahim and L.J.P. van der Maaten, CrypTen: Secure Multi-Party Computation Meets Machine Learning, 2021, arXiv 2109.00984, visited at https://github.com/facebookresearch/CrypTen/tree/main/tutorials on 1 May 2024). \n",
    "\n",
    "The neural network was build and experimented by the author, assisted by the Claude, ChatGPT and Gemini Chatbots. (“Please suggest a PyTorch neural network architecture for binary classification”, Claude 3, Anthropic PBC, generated on 27 March 2024., “Please improve this neural network architecture for binary classification…”, ChatGPT (GPT-4), OpenAI, generated on 27 March 2024., “Why is the F2 score of the crypten model worse?”, Gemini, Google (Alphabet Inc.), generated on 30 March 2024.)\n",
    "\n",
    "Firstly, the necessary libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "import torch\n",
    "import crypten\n",
    "from crypten import mpc\n",
    "import crypten.communicator as comm\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from time import time\n",
    "import psutil\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# This line is to hide the GPU, as simulation of multiple processes performing SMPC only works on the CPU.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and preparation\n",
    "\n",
    "As with the plain text model, data is prepared for the usage in the crypten SMPC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transactions has shape: torch.Size([800000, 7])\n",
      "y_train_transactions has shape: torch.Size([800000])\n",
      "X_test_transactions has shape: torch.Size([200000, 7])\n",
      "y_test_transactions has shape: torch.Size([200000])\n"
     ]
    }
   ],
   "source": [
    "df_nn = pd.read_csv(\"card_transdata.csv\")\n",
    "\n",
    "train_transactions, test_transactions = train_test_split(df_nn, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_transactions = train_transactions.drop(columns=[\"fraud\"])\n",
    "y_train_transactions = torch.from_numpy(train_transactions.fraud.values).flatten(0)\n",
    "X_test_transactions = test_transactions.drop(columns=[\"fraud\"])\n",
    "y_test_transactions = torch.from_numpy(test_transactions.fraud.values).flatten(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_transactions = torch.from_numpy(pd.DataFrame(scaler.fit_transform(X_train_transactions), columns=X_train_transactions.columns, index=X_train_transactions.index).values)\n",
    "X_test_transactions = torch.from_numpy(pd.DataFrame(scaler.transform(X_test_transactions), columns=X_test_transactions.columns, index=X_test_transactions.index).values)\n",
    "\n",
    "print(f\"X_train_transactions has shape: {X_train_transactions.shape}\")\n",
    "print(f\"y_train_transactions has shape: {y_train_transactions.shape}\")\n",
    "print(f\"X_test_transactions has shape: {X_test_transactions.shape}\")\n",
    "print(f\"y_test_transactions has shape: {y_test_transactions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crypten neural network architecture\n",
    "\n",
    "Below the crypten neural network architecture is defined, which is identical to the pytorch plaintext architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptenFraudDetectionModel(crypten.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(CryptenFraudDetectionModel, self).__init__()\n",
    "        self.fc1 = crypten.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = crypten.nn.ReLU()\n",
    "        self.dropout = crypten.nn.Dropout(0.5)\n",
    "        self.bn1 = crypten.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = crypten.nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu = crypten.nn.ReLU()\n",
    "        self.bn1 = crypten.nn.BatchNorm1d(hidden_size)\n",
    "        self.fc3 = crypten.nn.Linear(hidden_size, num_classes)\n",
    "        self.bn2 = crypten.nn.BatchNorm1d(num_classes)\n",
    "        self.sigmoid = crypten.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "input_size = 7\n",
    "hidden_size = 64\n",
    "num_classes = 1\n",
    "model = CryptenFraudDetectionModel(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crypten initialization\n",
    "\n",
    "Below, the crypten and torch libraries are initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of the data and encryption into multiparty computation tensors\n",
    "\n",
    "The code below splits the data set into 4 parts, simulating 4 parties. The dataset are encrypted into secret shares, using arithmetic and binary secret sharing. The datasets are then stored as .pth files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank1 = 0\n",
    "bank2 = 1\n",
    "bank3 = 2\n",
    "bank4 = 3\n",
    "\n",
    "# Specify file locations to save data for each bank\n",
    "filenames = {\n",
    "    \"X_samples_bank1\": \"data/X_samples_bank1.pth\",\n",
    "    \"X_samples_bank2\": \"data/X_samples_bank2.pth\",\n",
    "    \"X_samples_bank3\": \"data/X_samples_bank3.pth\",\n",
    "    \"X_samples_bank4\": \"data/X_samples_bank4.pth\",\n",
    "    \"y_samples_bank1\": \"data/y_samples_bank1.pth\",\n",
    "    \"y_samples_bank2\": \"data/y_samples_bank2.pth\",\n",
    "    \"y_samples_bank3\": \"data/y_samples_bank3.pth\",\n",
    "    \"y_samples_bank4\": \"data/y_samples_bank4.pth\",\n",
    "}\n",
    "\n",
    "@mpc.run_multiprocess(world_size=4)\n",
    "def save_all_data():   \n",
    "    # Save split dataset for the 4 banks\n",
    "    X_samples_bank1 = X_train_transactions[:12500]\n",
    "    X_samples_bank2 = X_train_transactions[12500:25000]\n",
    "    X_samples_bank3 = X_train_transactions[25000:37500]\n",
    "    X_samples_bank4 = X_train_transactions[37500:50000]\n",
    "    crypten.save_from_party(X_samples_bank1, filenames[\"X_samples_bank1\"],src = bank1)\n",
    "    crypten.save_from_party(X_samples_bank2, filenames[\"X_samples_bank2\"],src = bank2)\n",
    "    crypten.save_from_party(X_samples_bank3, filenames[\"X_samples_bank3\"],src = bank3)\n",
    "    crypten.save_from_party(X_samples_bank4, filenames[\"X_samples_bank4\"],src = bank4)\n",
    "\n",
    "    y_samples_bank1 = y_train_transactions[:12500]\n",
    "    y_samples_bank2 = y_train_transactions[12500:25000]\n",
    "    y_samples_bank3 = y_train_transactions[25000:37500]\n",
    "    y_samples_bank4 = y_train_transactions[37500:50000]\n",
    "    crypten.save_from_party(y_samples_bank1, filenames[\"y_samples_bank1\"],src = bank1)\n",
    "    crypten.save_from_party(y_samples_bank2, filenames[\"y_samples_bank2\"],src = bank2)\n",
    "    crypten.save_from_party(y_samples_bank3, filenames[\"y_samples_bank3\"],src = bank3)\n",
    "    crypten.save_from_party(y_samples_bank4, filenames[\"y_samples_bank4\"],src = bank4)\n",
    "    \n",
    "    \n",
    "save_all_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the neural network model\n",
    "\n",
    "The function below loads the data and trains the crypten neural network model. The model can be trained with the GPU, when the model is trained in one process without isolation.\n",
    "\n",
    "However, a multiparty computation can be simulated by using the @mpc.run_multiprocess(world_size=4), which simulates 4 isolated processes training the model. A crypten model can only be trained when its parameters are also encrypted. For the evaluation CPU is used, as simulation with 4 parties does not support the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mpc.run_multiprocess(world_size=4)\n",
    "def encrypted_training():\n",
    "    # Load data:\n",
    "    x_bank1_enc = crypten.load_from_party(filenames['X_samples_bank1'], src=bank1)\n",
    "    x_bank2_enc = crypten.load_from_party(filenames['X_samples_bank2'], src=bank2)\n",
    "    x_bank3_enc = crypten.load_from_party(filenames['X_samples_bank3'], src=bank3)\n",
    "    x_bank4_enc = crypten.load_from_party(filenames['X_samples_bank4'], src=bank4)\n",
    "\n",
    "    y_bank1_enc = crypten.load_from_party(filenames['y_samples_bank1'], src=bank1)\n",
    "    y_bank2_enc = crypten.load_from_party(filenames['y_samples_bank2'], src=bank2)\n",
    "    y_bank3_enc = crypten.load_from_party(filenames['y_samples_bank3'], src=bank3)\n",
    "    y_bank4_enc = crypten.load_from_party(filenames['y_samples_bank4'], src=bank4)\n",
    "    \n",
    "    model.encrypt()\n",
    "    # Set train mode\n",
    "    model.train()\n",
    "\n",
    "    # Combine the feature sets\n",
    "    x_combined_enc = crypten.cat([x_bank1_enc, x_bank2_enc, x_bank3_enc, x_bank4_enc], dim=0)\n",
    "    y_combined_enc= crypten.cat([y_bank1_enc, y_bank2_enc, y_bank3_enc, y_bank4_enc], dim=0)\n",
    "    crypten.print(x_combined_enc.size())\n",
    "    crypten.print(y_combined_enc.size())\n",
    "\n",
    "    loss = crypten.nn.loss.BCELoss()\n",
    "    rank = comm.get().get_rank()\n",
    "\n",
    "    # Define training parameters\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 5\n",
    "    batch_size = 32\n",
    "    num_batches = x_combined_enc.size(0) // batch_size\n",
    "    \n",
    "    for i in tqdm(range(num_epochs)):   \n",
    "    \n",
    "        for batch in range(num_batches):\n",
    "            # Define the start and end of the training mini-batch\n",
    "            start, end = batch * batch_size, (batch + 1) * batch_size\n",
    "                                    \n",
    "            # Construct CrypTensors out of training examples / labels\n",
    "            x_train = x_combined_enc[start:end]\n",
    "            x_train.requires_grad = True\n",
    "\n",
    "            y_train = y_combined_enc[start:end]\n",
    "            y_train.requires_grad = True\n",
    "\n",
    "            # Perform forward pass\n",
    "            output = model(x_train)\n",
    "            loss_value = loss(output, y_train.unsqueeze(1))\n",
    "            \n",
    "            # Set gradients to \"zero\" \n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform backward pass: \n",
    "            loss_value.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            model.update_parameters(learning_rate)\n",
    "            \n",
    "            # Print progress every batch:\n",
    "            \n",
    "        batch_loss = loss_value.get_plain_text()\n",
    "        accuracy = accuracy_score(np.where(output.get_plain_text() > 0.5, 1, 0), y_train.get_plain_text())\n",
    "        f2_score = fbeta_score(np.where(output.get_plain_text() > 0.5, 1, 0), y_train.get_plain_text(), beta=0.5)\n",
    "        crypten.print(f\"Loss at epoch {i} {batch_loss.item():.4f}\")\n",
    "        crypten.print(f\"Accuracy at epoch {i} {accuracy:.4f}\")\n",
    "        crypten.print(f\"F2 score at epoch {i} {f2_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the training of the encrypted model is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 7])\n",
      "torch.Size([50000])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b9e82bf0964c139924fd8e156c6a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 0.4489\n",
      "Accuracy at epoch 0 0.9375\n",
      "F2 score at epoch 0 0.8333\n",
      "Loss at epoch 1 0.3912\n",
      "Accuracy at epoch 1 0.9375\n",
      "F2 score at epoch 1 0.5000\n",
      "Loss at epoch 2 0.3096\n",
      "Accuracy at epoch 2 0.9375\n",
      "F2 score at epoch 2 0.5000\n",
      "Loss at epoch 3 0.2710\n",
      "Accuracy at epoch 3 0.9375\n",
      "F2 score at epoch 3 0.5000\n",
      "Loss at epoch 4 0.2702\n",
      "Accuracy at epoch 4 0.9375\n",
      "F2 score at epoch 4 0.5000\n",
      "Training of the neural network took 11269 seconds\n",
      "Memory usage difference: 2187264 bytes\n"
     ]
    }
   ],
   "source": [
    "# Measure time\n",
    "t_start = time()\n",
    "# Measure resource usage\n",
    "mem_usage = psutil.Process().memory_info().rss\n",
    "encrypted_training()\n",
    "mem_usage_end = psutil.Process().memory_info().rss\n",
    "\n",
    "# Calculate the differences\n",
    "mem_diff = mem_usage_end - mem_usage\n",
    "t_end = time()\n",
    "print(f\"Training of the neural network took {int(t_end - t_start)} seconds\")\n",
    "print(f\"Memory usage difference: {mem_diff} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the crypten model is evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.413385\n",
      "F1 score: 0.36032831875372057\n"
     ]
    }
   ],
   "source": [
    "model.encrypt()\n",
    "model.eval()\n",
    "output_test = model(crypten.cryptensor(X_test_transactions))\n",
    "output_test = output_test.get_plain_text()\n",
    "\n",
    "# Calculate accuracy and f1 score\n",
    "accuracy = accuracy_score(np.where(output_test > 0.5, 1, 0), y_test_transactions)\n",
    "f1_test = fbeta_score(np.where(output_test > 0.5, 1, 0), y_test_transactions, beta=0.5)\n",
    "print(\"Accuracy score: {}\".format(accuracy))\n",
    "print(\"F1 score: {}\".format(f1_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
