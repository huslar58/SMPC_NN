{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: onnx in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (1.16.0)\n",
      "Requirement already satisfied: filelock in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: numpy>=1.20 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from onnx) (5.26.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /workspaces/LR_tenseal/.venv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade torch onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "import crypten\n",
    "from crypten import mpc\n",
    "import crypten.communicator as comm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transactions has shape: torch.Size([800000, 7])\n",
      "y_train_transactions has shape: torch.Size([800000, 1])\n",
      "X_test_transactions has shape: torch.Size([200000, 7])\n",
      "y_test_transactions has shape: torch.Size([200000, 1])\n"
     ]
    }
   ],
   "source": [
    "df_nn = pd.read_csv(\"card_transdata.csv\")\n",
    "\n",
    "train_transactions, test_transactions = train_test_split(df_nn, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_transactions = torch.from_numpy(train_transactions.drop(columns=[\"fraud\"]).values)\n",
    "y_train_transactions = torch.from_numpy(train_transactions.fraud.values).view(-1, 1)\n",
    "X_test_transactions = torch.from_numpy(test_transactions.drop(columns=[\"fraud\"]).values)\n",
    "y_test_transactions = torch.from_numpy(test_transactions.fraud.values).view(-1, 1)\n",
    "\n",
    "print(f\"X_train_transactions has shape: {X_train_transactions.shape}\")\n",
    "print(f\"y_train_transactions has shape: {y_train_transactions.shape}\")\n",
    "print(f\"X_test_transactions has shape: {X_test_transactions.shape}\")\n",
    "print(f\"y_test_transactions has shape: {y_test_transactions.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDetectionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, lr=0.001):\n",
    "        super(FraudDetectionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size, dtype=torch.float64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout_prob = 0.5\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes, dtype=torch.float64)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.fc1.weight.dtype)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout_prob, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[36.2172,  0.2478,  0.1814,  ...,  1.0000,  0.0000,  1.0000],\n",
      "        [20.6738,  0.5731,  0.6636,  ...,  1.0000,  0.0000,  1.0000],\n",
      "        [ 4.7852,  2.3890,  3.5380,  ...,  1.0000,  0.0000,  1.0000],\n",
      "        ...,\n",
      "        [62.9908,  0.4695,  0.9350,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 4.1692,  4.3749,  0.9618,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [30.5910, 12.0598,  0.7788,  ...,  1.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Specify file locations to save data for each bank\n",
    "filenames = {\n",
    "    \"X_samples_bank1\": \"data/X_samples_bank1.pth\",\n",
    "    \"X_samples_bank2\": \"data/X_samples_bank2.pth\",\n",
    "    \"X_samples_bank3\": \"data/X_samples_bank3.pth\",\n",
    "    \"X_samples_bank4\": \"data/X_samples_bank4.pth\",\n",
    "    \"y_samples_bank1\": \"data/y_samples_bank1.pth\",\n",
    "    \"y_samples_bank2\": \"data/y_samples_bank2.pth\",\n",
    "    \"y_samples_bank3\": \"data/y_samples_bank3.pth\",\n",
    "    \"y_samples_bank4\": \"data/y_samples_bank4.pth\",\n",
    "}\n",
    "\n",
    "print(X_train_transactions[:200000])\n",
    "\n",
    "def save_all_data():   \n",
    "    # Save split dataset for the 4 banks\n",
    "    X_samples_bank1 = X_train_transactions[:200000]\n",
    "    X_samples_bank2 = X_train_transactions[200000:400000]\n",
    "    X_samples_bank3 = X_train_transactions[400000:600000]\n",
    "    X_samples_bank4 = X_train_transactions[600000:800000]\n",
    "    crypten.save_from_party(X_samples_bank1, filenames[\"X_samples_bank1\"])\n",
    "    crypten.save_from_party(X_samples_bank2, filenames[\"X_samples_bank2\"])\n",
    "    crypten.save_from_party(X_samples_bank3, filenames[\"X_samples_bank3\"])\n",
    "    crypten.save_from_party(X_samples_bank4, filenames[\"X_samples_bank4\"])\n",
    "\n",
    "    y_samples_bank1 = y_train_transactions[:200000]\n",
    "    y_samples_bank2 = y_train_transactions[200000:400000]\n",
    "    y_samples_bank3 = y_train_transactions[400000:600000]\n",
    "    y_samples_bank4 = y_train_transactions[600000:800000]\n",
    "    crypten.save_from_party(y_samples_bank1, filenames[\"y_samples_bank1\"])\n",
    "    crypten.save_from_party(y_samples_bank2, filenames[\"y_samples_bank2\"])\n",
    "    crypten.save_from_party(y_samples_bank3, filenames[\"y_samples_bank3\"])\n",
    "    crypten.save_from_party(y_samples_bank4, filenames[\"y_samples_bank4\"])\n",
    "    \n",
    "    \n",
    "save_all_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 7  # Number of input features\n",
    "hidden_size = 64  # Number of hidden units\n",
    "num_classes = 1  # Binary classification\n",
    "num_epochs = 1500\n",
    "\n",
    "torch_model = FraudDetectionModel(input_size, hidden_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "CheckerError",
     "evalue": "Unrecognized attribute: ratio for operator Dropout\n\n==> Context: Bad node spec for node. Name: /dropout/Dropout OpType: Dropout",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/workspaces/LR_tenseal/.venv/lib/python3.9/site-packages/torch/onnx/utils.py:1702\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1702\u001b[0m     \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_onnx_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unrecognized attribute: ratio for operator Dropout\n\n==> Context: Bad node spec for node. Name: /dropout/Dropout OpType: Dropout",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCheckerError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m             batch_loss \u001b[38;5;241m=\u001b[39m loss_value\u001b[38;5;241m.\u001b[39mget_plain_text()\n\u001b[1;32m     61\u001b[0m             crypten\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(batch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[43mencrypted_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mencrypted_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m y_bank4_enc \u001b[38;5;241m=\u001b[39m crypten\u001b[38;5;241m.\u001b[39mload_from_party(filenames[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_samples_bank4\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m200000\u001b[39m, \u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcrypten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mencrypt()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Set train mode\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/LR_tenseal/.venv/lib/python3.9/site-packages/crypten/nn/onnx_converter.py:57\u001b[0m, in \u001b[0;36mfrom_pytorch\u001b[0;34m(pytorch_model, dummy_input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03mConverts a PyTorch model `pytorch_model` into a CrypTen model by tracing it\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03musing the input `dummy_input`.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# construct CrypTen model:\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43m_from_pytorch_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpytorch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m crypten_model \u001b[38;5;241m=\u001b[39m from_onnx(f)\n\u001b[1;32m     59\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/workspaces/LR_tenseal/.venv/lib/python3.9/site-packages/crypten/nn/onnx_converter.py:128\u001b[0m, in \u001b[0;36m_from_pytorch_to_bytes\u001b[0;34m(pytorch_model, dummy_input)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# export again so the graph is created with CrypTen-specific registry:\u001b[39;00m\n\u001b[1;32m    127\u001b[0m f \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m--> 128\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43m_export_pytorch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpytorch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m f\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/workspaces/LR_tenseal/.venv/lib/python3.9/site-packages/crypten/nn/onnx_converter.py:146\u001b[0m, in \u001b[0;36m_export_pytorch_model\u001b[0;34m(f, pytorch_model, dummy_input)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mReturns a binary I/O stream containing ONNX-exported pytorch_model that was\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03mtraced with input `dummy_input`.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_constant_folding\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport_params\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopset_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: _OPSET_VERSION,\n\u001b[1;32m    145\u001b[0m }\n\u001b[0;32m--> 146\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpytorch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/workspaces/LR_tenseal/.venv/lib/python3.9/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/LR_tenseal/.venv/lib/python3.9/site-packages/torch/onnx/utils.py:1704\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                 _C\u001b[38;5;241m.\u001b[39m_check_onnx_proto(proto)\n\u001b[1;32m   1703\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1704\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mCheckerError(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1706\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m GLOBALS\u001b[38;5;241m.\u001b[39min_onnx_export\n",
      "\u001b[0;31mCheckerError\u001b[0m: Unrecognized attribute: ratio for operator Dropout\n\n==> Context: Bad node spec for node. Name: /dropout/Dropout OpType: Dropout"
     ]
    }
   ],
   "source": [
    "def encrypted_training():\n",
    "    # Load data:\n",
    "    x_bank1_enc = crypten.load_from_party(filenames['X_samples_bank1'])\n",
    "    x_bank2_enc = crypten.load_from_party(filenames['X_samples_bank2'])\n",
    "    x_bank3_enc = crypten.load_from_party(filenames['X_samples_bank3'])\n",
    "    x_bank4_enc = crypten.load_from_party(filenames['X_samples_bank4'])\n",
    "\n",
    "    y_bank1_enc = crypten.load_from_party(filenames['y_samples_bank1'])\n",
    "    y_bank2_enc = crypten.load_from_party(filenames['y_samples_bank2'])\n",
    "    y_bank3_enc = crypten.load_from_party(filenames['y_samples_bank3'])\n",
    "    y_bank4_enc = crypten.load_from_party(filenames['y_samples_bank4'])\n",
    "    dummy_input = torch.randn(200000, 7)\n",
    "    model = crypten.nn.from_pytorch(torch_model,dummy_input)\n",
    "    model.encrypt()\n",
    "    # Set train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Combine the feature sets: identical to Tutorial 3\n",
    "    x_combined_enc = crypten.cat([x_bank1_enc, x_bank2_enc, x_bank3_enc, x_bank4_enc], dim=1)\n",
    "    y_combined_enc = crypten.cat([y_bank1_enc, y_bank2_enc, y_bank3_enc, y_bank4_enc], dim=1)\n",
    "    \n",
    "    # Reshape to match the network architecture\n",
    "    x_combined_enc = x_combined_enc.unsqueeze(1)\n",
    "    y_combined_enc = y_combined_enc.unsqueeze(1)\n",
    "\n",
    "    loss = crypten.nn.BCELoss()\n",
    "\n",
    "        # Define training parameters\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 2\n",
    "    batch_size = 10\n",
    "    num_batches = x_combined_enc.size(0) // batch_size\n",
    "    \n",
    "    for i in range(num_epochs): \n",
    "        crypten.print(f\"Epoch {i} in progress:\")       \n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            # define the start and end of the training mini-batch\n",
    "            start, end = batch * batch_size, (batch + 1) * batch_size\n",
    "                                    \n",
    "            # construct CrypTensors out of training examples / labels\n",
    "            x_train = x_combined_enc[start:end]\n",
    "            y_train = y_combined_enc[start:end]\n",
    "            # y_train = crypten.cryptensor(y_batch, requires_grad=True)\n",
    "            \n",
    "            # perform forward pass:\n",
    "            output = model(x_train)\n",
    "            loss_value = loss(output, y_train)\n",
    "            \n",
    "            # set gradients to \"zero\" \n",
    "            model.zero_grad()\n",
    "\n",
    "            # perform backward pass: \n",
    "            loss_value.backward()\n",
    "\n",
    "            # update parameters\n",
    "            model.update_parameters(learning_rate)\n",
    "            \n",
    "            # Print progress every batch:\n",
    "            batch_loss = loss_value.get_plain_text()\n",
    "            crypten.print(f\"\\tBatch {(batch + 1)} of {num_batches} Loss {batch_loss.item():.4f}\")\n",
    "\n",
    "encrypted_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
